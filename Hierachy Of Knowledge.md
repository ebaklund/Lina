### Dispositional dimensions
- Narrative: Expositional development
    - What
        - The problem: Language oriented, not knowledge oriented
        - Goal: Relevance, coherence, performance
        - Workflow: From learning to chat bot 
    - How
        - Mechanisms: Labeling,
        - Implementation: Encodings, layers, networks, transformations, aggregations, serialization 

This repo contains my notes that are generated in the 
process for me to understand this problem area.

Here are the main ideas about information that are explored:
- Prior art
  - Logic
  - Quantum physics
  - Newtonian physics
  - Information theory
  - Linguistics
  - Consciousness and qualia
  - Large Language Models
  - Situational calculus

---

# Hierarchy of knowledge

## Introduction
LLMs are word oriented, not knowledge oriented.
The currently most popular AIs are based on LLM that generates text word-for-word based on
learned statistical probabilities. 
LLMs are good at paraphrasing previously seen text, but do not have any capacity 
to convey, preserve, or guarantee logical relevance or coherence.
This is a very well known problem in the AI research community.

The reason that this problem has not been solved is not because it has avoided,
but because the problem is hard. The theoretical aspect is hard and the implementation aspect is hard.

AI research has largely been inspired by academic fields like statistics, linear algebra, and logic.
However, those fields have not been developed with knowledge processing in mind and 
the educational institutions tend to teach those subjects in isolation.
That means that applying those academic fields in AI research, requires extra research to
adapt existing academic fields to usable frameworks for AI development.



## The problem with Logic
Achieving logical coherence in artificial systems is essential,
but the academic field of logic often falls short because its
mainstream research is overly fixated on idealized,
binary truth systems (True/False).

This simplistic, dualistic constraint fails to capture the richness of real-world information,<br> 
leading many logicians to attempt incremental patches
by adding extra operations and primitives which ultimately
introduce new complexities and fractures rather than
providing a robust foundation for practical AI.

## Logic as a human construct
While the classical philosophical approach treats logic and truth systems as foundational, 
my opinion is that truth is not a core element of the world's structure, 
but is at best emergent, and perhaps fundamentally weaker than that. 

My view is that the intense historical focus on truth-systems stems not from their objective foundation, 
but from their powerful connection to essential human notions of meaning and morality that classical thinkers grappled with. 

Consequently, truth is not a structural primitive of reality, 
but rather a vital cognitive and mental tool — 
a human phenomena that motivates academic logic — 
essential for humanity's ability to navigate and survive in the world. 

## Emergent Logic
Since I do not accept Logic truth systems as fundamental but necessary,
how can we construct Logical truth systems from something more fundamental?

That one is easy, we do not need to look further that the resource tools that 
scientist use to create models of the real world.
Scientists relies strongly on scientific experiments and measurement which results
are adhered and processed with statistical analysis.

From that analysis they derive correlations and causalities which further
inspires creation of consistent models.
The physical models are an analog to the logical models the philosophers deal with. 
Good physical models are recognized to the degree they are able to predict the behavior of the physical system they model.
But - they are always descriptive and operate with some error.
They are always statistical, even if its not evident their formulation expression where the tiny errors are for the most practical applications is ignored.

It is in this physical world that any living organism must be able to model
the environment they live in, and how to interact with it, to maximize the chance of survival.

Any organism must internalize such a model, but notice; whatever the model is,
it is a physical model of the organism's environment and organism's place in it.
There is no place here for the metaphysical human concept of truth.
Instead, we have correlations between the real world and the model of the organism.
The level of correlation is vital for it's survival.

## Information
I have up to now

